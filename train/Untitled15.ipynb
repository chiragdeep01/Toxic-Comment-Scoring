{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIueBy_rrwE7",
        "outputId": "0f9cea6e-4cbe-4d88-d826-88f9ab40eead"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "%pip install contractions\n",
        "import contractions\n",
        "import numpy as np\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdoN3gq4v-of"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('data/train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsROgtiqwA4H"
      },
      "outputs": [],
      "source": [
        "class Text:\n",
        "\n",
        "    def remove_numbers_and_non_english(self, text):\n",
        "\n",
        "        text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "        # Remove non-English characters (assuming English alphabet)\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "        return text\n",
        "\n",
        "    def expand_contractions(self, text):\n",
        "        expanded_text = contractions.fix(text)\n",
        "\n",
        "        return expanded_text\n",
        "\n",
        "    def remove_extraSpace(self, text):\n",
        "        text = re.sub(' +', ' ', text)\n",
        "        # Remove trailing and leading whitespaces in string\n",
        "        text = text.strip()\n",
        "        return text\n",
        "\n",
        "    def remove_newline(self, text):\n",
        "        text = text.replace(\"\\n\", \" \")\n",
        "        return text\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess(text):\n",
        "        instance = Text()\n",
        "        text = instance.remove_newline(text)\n",
        "        text = instance.expand_contractions(text)\n",
        "        text = instance.remove_numbers_and_non_english(text)\n",
        "        text = instance.remove_extraSpace(text)\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJwkivjAwC7m"
      },
      "outputs": [],
      "source": [
        "data['comment_text'] = data['comment_text'].apply(Text.preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHwPZhBdwLxc"
      },
      "outputs": [],
      "source": [
        "X = data['comment_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlrCW1VNxQfe"
      },
      "outputs": [],
      "source": [
        "y = data.iloc[:, 2:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mlusBISxdtB"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bn7DldGWxhgG"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X,y ,\n",
        "                                   random_state=42,\n",
        "                                   test_size=0.2,\n",
        "                                   shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4hwhooEyp04",
        "outputId": "9b364062-941f-47bd-a828-22cc81942102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "232534\n"
          ]
        }
      ],
      "source": [
        "vocab = set()\n",
        "for sentence in X_train:\n",
        "    for word in sentence.split():\n",
        "        vocab.add(word)\n",
        "\n",
        "print(len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMM2R2xPzqex"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWLWvZ5G2tHp"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36QzA_W62_oy",
        "outputId": "0429edd1-59ff-47bb-c275-58a2bb32e5a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.src.preprocessing.text.Tokenizer at 0x789f3ede6170>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4K1kt1_E3J70"
      },
      "outputs": [],
      "source": [
        "X_train_tokenized = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_tokenized = tokenizer.texts_to_sequences(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FVmWl9m3VmW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "train_sequences = pad_sequences(X_train_tokenized, maxlen=300,\n",
        "                                padding=\"post\", truncating=\"post\")\n",
        "val_sequences = pad_sequences(X_val_tokenized, maxlen=300,\n",
        "                              padding=\"post\", truncating=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abbuO_KINuxF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, TextVectorization, Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkLZFDuFNzIt"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    Embedding(25000, 200, input_length=300),\n",
        "    LSTM(16, activation=\"tanh\"),\n",
        "    Dense(6, activation=\"sigmoid\"), # we are predicting for 6 classes\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ4abiDyOHzZ",
        "outputId": "130ea068-ca62-4ff4-847a-068496964d64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 300, 200)          5000000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 16)                13888     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 102       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5013990 (19.13 MB)\n",
            "Trainable params: 5013990 (19.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx7TA-U-OKAk"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rhqys-cDRoKW"
      },
      "outputs": [],
      "source": [
        "epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZi2_GlMRplV",
        "outputId": "ea67bf58-289e-47a9-8bf7-3d4eaebeddaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1995/1995 [==============================] - 175s 84ms/step - loss: 0.1500 - accuracy: 0.9457 - val_loss: 0.1408 - val_accuracy: 0.9939\n",
            "Epoch 2/5\n",
            "1995/1995 [==============================] - 50s 25ms/step - loss: 0.1398 - accuracy: 0.9938 - val_loss: 0.1406 - val_accuracy: 0.9940\n",
            "Epoch 3/5\n",
            "1995/1995 [==============================] - 41s 20ms/step - loss: 0.1353 - accuracy: 0.9930 - val_loss: 0.1403 - val_accuracy: 0.9940\n",
            "Epoch 4/5\n",
            "1995/1995 [==============================] - 37s 19ms/step - loss: 0.1369 - accuracy: 0.9941 - val_loss: 0.0976 - val_accuracy: 0.9938\n",
            "Epoch 5/5\n",
            "1995/1995 [==============================] - 35s 17ms/step - loss: 0.0667 - accuracy: 0.9898 - val_loss: 0.0573 - val_accuracy: 0.9941\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x789f216a8880>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 64\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=3),\n",
        "]\n",
        "\n",
        "# model.evaluate(X_val, y_val)\n",
        "\n",
        "model.fit(\n",
        "    train_sequences,\n",
        "    y_train,\n",
        "    validation_data=(val_sequences, y_val),\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=callbacks,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jv00o30SDio",
        "outputId": "a528928d-06a2-4347-c5d3-1c6f290e0098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Saved!\n"
          ]
        }
      ],
      "source": [
        "model.save_weights('weights.h5')\n",
        "print('Model Saved!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqH-LEkdbPa7"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# saving\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QU_aKQWx-Sv7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
